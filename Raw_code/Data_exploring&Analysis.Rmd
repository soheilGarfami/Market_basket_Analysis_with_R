---
title: "Data exploring and analysis"
author: "Soheil Garfami"
date: "2024-08-17"
output: 
  html_document: 
    toc: true
---
# **introduction**

Welcome to the Market Basket Analysis with R! In this markdown document, we will explore a dataset of grocery store transactions, conduct analysis, create visualizations, and derive insights. In a [follow-up markdown](Market_basket_analysis.html), we will dive deeper by applying the Apriori algorithm to uncover valuable associations within the data.

### Key Objectives
The primary goals of this analysis are to:


- **Understand customer purchasing behaviors and patterns**  

- **Identify key insights to enhance the shopping experience**  

- **Improve product placement and identify opportunities for upselling**   


### Business Questions of Interest:
Some of the key business questions we aim to answer include:  

- What are the most popular items purchased, and which are the least popular?  
 
- What does the distribution of purchased products look like?  

- Are there any items that are frequently purchased together, and what are the strongest product pairings?  

- How can we leverage this information to recommend additional products based on a customer's shopping cart?  


### Dataset Overview
For this analysis, we will be working with a dataset from the Instacart Market Basket Analysis competition on Kaggle [link to the dataset](https://www.kaggle.com/c/instacart-market-basket-analysis). This dataset includes the following five files, each providing valuable insights:


- **aisles.csv**: Information on the aisles where products are located.  

- **departments.csv**: Details on product departments.  

- **order_products.csv**: Data on the specific products purchased in each order.  

- **orders.csv**: Records of customer orders.  

- **products.csv**: Details on individual products.

Without further ado, letâ€™s dive in and begin exploring the data!  




# **Data exploring**


first lets import some libraries that we are going to use. 
```{r message=FALSE, warning=FALSE}
library(tidyverse)
library(ggplot2)
library(DataExplorer)
library(lubridate)
```

```{r setup, include=FALSE}
knitr::opts_chunk$set(
  message = FALSE,
  warning = FALSE,
  echo = TRUE,  
  results = 'show' 
)
```
Importing Datasets:

```{r}
orders_products <- read.csv("data/order_products__train.csv")
orders <- read.csv("data/orders.csv")
products <- read.csv("data/products.csv")
aisles <- read.csv("data/aisles.csv")
departments <- read.csv("data/departments.csv")
```
### Dataset: order_products
Let's take a look at this dataset.

```{r}
glimpse(orders_products)
```

Let's examine how many orders and products we have.
```{r}
length(unique(orders_products$order_id)) 
length(unique(orders_products$product_id))

```
<hr>

**Let's examine the distribution of the number of products in orders.**


```{r warning=FALSE}
n_product_by_orders <- orders_products %>% 
  group_by(order_id) %>% 
  summarise(n_product= n()) 


summary(n_product_by_orders$n_product)

```
As you can see, the minimum number of products in an order is 1, while the maximum is 80. Let's explore some `visualizations` to gain further insights.

```{r}
n_product_by_orders %>% 
  ggplot(aes(n_product))+
  geom_histogram(binwidth = 1 ,fill="#8ea3a3" , color='#a4c445')+
  labs(title = "distribution of the number of products")
```

<hr>



Let's create a report for this dataset.

```{r eval=FALSE, message=FALSE, warning=FALSE, include=TRUE}
create_report(orders_products, 
              output_file = "reports/orders_products_report.html", 
              y = NULL, 
              config = configure_report(add_plot_missing = F,
                                        add_plot_intro=F,
                                        add_plot_str = F,
                                        add_plot_correlation = F,
              )
)
```




take a look at the [report for order-product](reports/orders_products_report.html)


```{r}
#Since we no longer need the variable `n_product_by_orders`, let's remove it from memory to clean up.

rm(n_product_by_orders)
```


<hr>


### Dataset: orders

```{r}
head(orders)

``` 

<hr>


**Let's analyze the time intervals between orders**

```{r}
summary(orders$days_since_prior_order)

#Let's see the percentage of data entries without `days_since_prior_order`.
round(sum(is.na(orders$days_since_prior_order))/nrow(orders) , 2)
```

Some of these missing values might be due to first-time purchases, but overall, it's not a large proportion.


```{r warning=FALSE}
ggplot(orders , aes(days_since_prior_order))+geom_histogram(fill="gray" , color="darkblue" )+
  labs(title = "distribution of the gap between orders")
```

<hr>

**Let's see the distribution of orders by hour of the day.**


```{r warning=FALSE}
ggplot(orders , aes(order_hour_of_day))+geom_histogram(fill="gray" ,binwidth = 1, color="#DE3163" )+
  labs(title = "distribution number of orders in each hour")

```

<hr>


**orders in days of the week**

```{r warning=FALSE}
hist(orders$order_dow,          # "Suggests" 14 bins
     freq   = FALSE,       # Axis shows density, not freq.
     col    = "thistle1",  # Color for histogram
     main   = paste("Histogram of Annual Canadian Lynx",
                    "Trappings, 1821-1934"),
     xlab   = "Number of Lynx Trapped")

```

it seems like we get a few more orders in the first tow days of the week 

```{r eval=FALSE, message=FALSE, warning=FALSE, include=TRUE}
create_report(orders, 
              output_file = "reports/orders.html", 
              y = NULL, 
              config = configure_report(
                                        add_plot_intro=F,
                                        add_plot_str = F,
              ))

```


check out the [report for the orders](reports/orders.html)

<hr>

### Dataset: products

have look at the data set
```{r}
glimpse(products)
```

Let's examine the proportion of products that are `organic` versus `non-organic`.



```{r}
products %>%
  mutate(type = ifelse(grepl("Organic", product_name) , "organic" ,"non-organic")) %>%
  group_by(type) %>%
  summarise(count = n(), .groups = 'drop') %>%  # Added .groups = 'drop' to avoid warning
  ggplot(aes(x = "", y = count, fill = type)) +
  geom_bar(width = 1, stat = "identity") +
  coord_polar(theta = "y") +
  labs(title = "Proportion of Organic vs Non-Organic Products") +
  theme_void() +
  scale_fill_manual(values = c("organic" = "lightgreen", "non-organic" = "#f1948a"))
```



```{r eval=FALSE, message=FALSE, warning=FALSE, include=TRUE}
create_report(orders, 
              output_file = "reports/products_report.html" , 
              y = NULL,  )
```


check out the [report for the products ](reports/products_report.html)

<hr>



### Dataset: aisles and departments 
```{r}
head(aisles)

```


```{r}
head(departments)
```


Let's now join all the datasets together to build a complete dataset.
```{r warning=FALSE}
JOINED <- inner_join(orders_products , orders , by="order_id")
JOINED <- inner_join(JOINED , products , "product_id")
JOINED <- inner_join(JOINED , aisles , "aisle_id")
JOINED <- inner_join(JOINED , departments , "department_id")

write.csv(JOINED , "data/JOINED.csv" , row.names = F)

View(head(JOINED))
```


```{r}
ncol(JOINED)
nrow(JOINED)
```


<hr>


# **Analizing the Data**

Now, we are going to use the joined dataset to uncover `insights` and create `visualizations`.


let's build a frequency table and see the most popular products 

```{r message=FALSE, warning=FALSE}
frequency_product <- JOINED %>% 
  group_by(product_name ) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count))

top_n(frequency_product , 10)

```

yeyy banana , I love banana :)

lets see the most popular aisles 

```{r message=FALSE, warning=FALSE}
frequency_aisle <- JOINED %>% 
  group_by(aisle ) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count))

top_n(frequency_aisle , 10)

```


```{r message=FALSE, warning=FALSE}
JOINED %>% 
  group_by(product_name, aisle ) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count)) %>% 
  head() %>% 
  ggplot(aes(x = reorder(product_name , count) , y = count, fill = aisle))+
  geom_bar(stat = "identity")+
  coord_flip()+
  labs(title = "top 6 most purchased products and their aisle")
```

<hr>


Let's check if there are any products that were purchased only once.

```{r}
frequency_product %>% 
  filter(count == 1)
```

Let's examine the percentage of one-time-purchased products in the dataset.

```{r}
frequency_product %>% 
  filter(count == 1) %>% 
  nrow() / nrow(frequency_product)
```




```{r}
frequency_product <-  frequency_product %>% 
  mutate(percent = count / nrow(frequency_product)) %>% 
  mutate(rank = rank(desc(count))) 

head(frequency_product)
```

Let's examine the number of purchases made by each customer and sort them from highest to lowest to identify the maximum.


```{r}
JOINED %>% 
  group_by(user_id ) %>% 
  summarise(numberOfPurches = n()) %>% 
  arrange(desc(numberOfPurches))
  
```

<hr>


Now that we have a good understanding of the data and have extracted some valuable insights, the next step is to conduct a market basket analysis to discover potential correlation rules. 

Check out the [Market Basket Analysis](Market_basket_analysis.html) kernel.




